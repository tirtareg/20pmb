# calculate performance
prediction$confusion
prediction$data
prediction$data$row_ids
prediction$data$response
measure <- msr("classif.acc")
measure
?msr
measure <- msr("classif.acc")
prediction$score(measure)
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
measure <- msr("classif.auc")
prediction$score(measure)
prediction$score()
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 3L)
resampling
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
knitr::opts_chunk$set(echo = TRUE)
library(mlr3)
# create learning task
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris
# load learner and set hyperparameter
learner <- lrn("classif.rpart", cp = 0.01)
learner
# train/test split
set.seed(100)
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)
# train the model
learner$train(task_iris, row_ids = train_set)
# predict data
prediction <- learner$predict(task_iris, row_ids = test_set)
# calculate performance
prediction$confusion
measure <- msr("classif.acc")
prediction$score(measure)
# automatic resampling
resampling <- rsmp("cv", folds = 5L)
rr <- resample(task_iris, learner, resampling)
rr$score(measure)
rr$aggregate(measure)
data("mtcars", package = "datasets")
data = mtcars[, 1:3]
str(data)
library("mlr3")
task_mtcars = TaskRegr$new(id = "cars", backend = data, target = "mpg")
print(task_mtcars)
task_mtcars
library("mlr3viz")
install.packages('mlr3viz', dependencies = T)
library("mlr3viz")
install.packages('vctrs', dependencies = T)
library("mlr3viz")
autoplot(task_mtcars, type = "pairs")
autoplot(task_mtcars, type = "pairs")
a <- autoplot(task_mtcars, type = "pairs")
ggsave(a)
ggplot2::ggsave(a)
rlang::last_error()
library(Cairo)
install.packages('Cairo')
library(Cairo)
Cairo::Cairo(
30, #length
30, #width
file = paste("nameofplot", ".png", sep = ""),
type = "png", #tiff
bg = "transparent", #white or transparent depending on your requirement
dpi = 300,
units = "cm" #you can change to pixels etc
)
plot(a) #p is your graph object
tinytex::install_tinytex()
mlr_tasks
mlr_tasks$get('pima')
print(mlr_tasks$get('pima'))
mlr_tasks$get('pima')$data()
mlr_tasks$get('iris')$data()
class(mlr_tasks$get('iris')$data())
mlr_tasks
as.data.table(mlr_tasks)
task_mtcars$missings()
task_mtcars$missings()
task_mtcars$man
task_mtcars$man()
task_mtcars$missings()
task_iris = mlr_tasks$get("iris")
print(task_iris)
tsk('iris')
tsk('iris')
tsk('iris')$data()
task_iris$data()
task_iris$data()
tsk('iris')$data()
task_iris$data()
dim(tsk('iris')$data())
str(tsk('iris')$data())
summary(task_iris)
summary(task_iris$data())
summary(tsk('iris'))
tsk('iris')
summary(tsk('iris')$data())
reticulate::repl_python()
print('nmaku')
Y
update.packages(ask = F, checkBuilt = T)
install.packages('rlang')
install.packages("rlang")
library(discretization)
install.packages("discretization")
library(discretization)
data(iris)
mdlp(iris)$Disc.data
a <- mdlp(iris)
a$cutp
a$cutp[1]
str(iris)
a
summary(a)
a
a <- mdlp(iris)
a
str(a)
a
class(a)
a
a$Disc.data
summary(a$Disc.data)
mdlp(iris)$cutp
mdlp(iris)$cutp[1]
a <- rnorm(130, 10, 2)
mdlp(a)$cutp
dim(iris)
iris
mdlp(iris[,c(1, 5)])
mdlp(iris[,c(1, 5)])$cutp
mdlp(iris[,c(1, 5)])$cutp[1]
c(-Inf, mdlp(iris[,c(1,5)$cutp[1]]), Inf)
c(-Inf, mdlp(iris[,c(1,5])$cutp[1]]), Inf)
c(-Inf, mdlp(iris[,c(1,5])$cutp[1]), Inf)
c(-Inf, mdlp(iris[,c(1,5)])$cutp[1]), Inf)
c(-Inf, mdlp(iris[,c(1,5)])$cutp[1], Inf)
mdlp(iris[,c(1,5)])$cutp[[1]]
c(-Inf, mdlp(iris[,c(1,5)])$cutp[[1]], Inf)
setwd("G:/My Drive/#PMB/2020/Dashboard/20pmb")
install.packages(c("data.table", "future.apply", "parallelly", "robustbase"))
